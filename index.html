<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://brian-moser.github.io/" target="_blank">Brian B. Moser</a><sup></sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.de/citations?user=Jx9-sU0AAAAJ&hl=en" target="_blank">Federico Raue</a><sup></sup>,</span>
                  <span class="author-block">
                    <a href="https://stanifrolov.github.io/" target="_blank">Stanislav Frolov</a>
                  </span>
                  <span class="author-block">
                    <a href="https://spalaciob.github.io/" target="_blank">Sebastian Palacio</a>
                  </span>
                  <span class="author-block">
                    <a href="https://joernhees.de/blog/" target="_blank">Jörn Hees</a>
                  </span>
                  <span class="author-block">
                    <a href="https://agd.cs.uni-kl.de/" target="_blank">Andreas Dengel</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Deutsches Forschungszentrum für Künstliche Intelligenz<br>RPTU Kaiserslautern-Landau<br>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10041995" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://ieeexplore.ieee.org/ielx7/34/4359286/10041995/supp1-3243794.pdf?arnumber=10041995" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2209.13131" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            With the advent of Deep Learning (DL), Super-Resolution (SR) has also become a thriving research area. However, despite promising results, the field still faces challenges that require further research e.g., allowing flexible upsampling, more effective loss functions, and better evaluation metrics. We review the domain of SR in light of recent advances, and examine state-of-the-art models such as diffusion (DDPM) and transformer-based SR models. We present a critical discussion on contemporary strategies used in SR, and identify promising yet unexplored research directions. We complement previous surveys by incorporating the latest developments in the field such as uncertainty-driven losses, wavelet networks, neural architecture search, novel normalization methods, and the latests evaluation techniques. We also include several visualizations for the models and methods throughout each chapter in order to facilitate a global understanding of the trends in the field. This review is ultimately aimed at helping researchers to push the boundaries of DL applied to SR.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <div class="content has-text-justified">
      <p style="text-align:center;">
        <img src="static/images/sr_framework.png" alt="MY ALT TEXT" width="50%" height="50%"/>
      </p>
      <p>
        Hold on to your lab coats, fellow scientists! This work will take you on a wild ride through the world of Super-Resolution (SR).
        In SR, the quest is to scale up a Low-Resolution (LR) image to a High-Resolution (HR) image.
        Our work will send you into a journey with the ins and outs of SR, diving into the basic concepts, state-of-the-art methods and new ideas for SR.
      </p>
      <p>
        The work commences with an introduction to the basic definitions and terminology.
        It then proceeds to discuss evaluation metrics for SR solutions.
        Along the way, you'll encounter various datasets that provide diverse data types, like 8K resolution images or video sequences.
        The adventure continues as you delve into learning objectives of Super-Resolution:
        Regression-based SR (also with uncertainty), Generative SR, and, more recently, Denoising Diffusion Probabilistic Models.
      </p>
      <p style="text-align:center;">
        <img src="static/images/udl.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
      <p>
        This work dives also into the world of various upsampling methods, a critical aspect in image SR.
        It covers the whys and hows of interpolation-based and learning-based upsampling techniques and also problems appearing with upsampling techniques (e.g., artifacts) in supplemental material.
        Also, our work explores the challenges and potential solutions of flexible upsampling for real-world scenarios with arbitrary scaling factors.
      </p>

      <p>
        You'll also learn about additional learning strategies such as curriculum learning, enhanced predictions, learned degradation, network fusion, multi-task learning, and normalization techniques like the Adaptive Deviation Modulator (AdaDM).
      </p>
      <p style="text-align:center;">
        <img src="static/images/MetaUpscale.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
      <p>
        But wait, there's more! Gather around, as we embark on an epic quest to unveil the mystic secrets for SR models and architectures!
        In this treacherous journey, we will first traverse the hallowed halls of upsampling location, unearthing four known and distinct artifacts:
        Pre-upsampling, Post-upsampling, Progressive Upsampling, and Iterative Up-and-Down Upsampling.
        These relics, as displayed in a mystical illustration, shall guide our understanding of the SR models' construction.
      </p>
      <p style="text-align:center;">
        <img src="static/images/frameworks.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
      <p>
        In this wondrous land, we'll encounter these primary categories: Simple Networks, Residual Networks, Recurrent-Based Networks, Lightweight and Wavelet-based Models.
        We shall explore various state-of-the-art architectures and discuss their pros and cons.
        Finally, you will get a scoop of Unsupervised SR and Neural Architecture Search for SR!
        At last, but not least, we will discuss the future of SR, and the challenges that lie ahead.
        So, gather your party and embark on this thrilling adventure, delving into the diverse and intricate world of deep learning-based super-resolution networks and unlock its secrets!
        Spoiler-Warning: Big tables included.
      </p>

      <p style="text-align:center;">
        <img src="static/images/table.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
    </div>
  </div>
</div>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@ARTICLE{10041995,
  author={Moser, Brian B. and Raue, Federico and Frolov, Stanislav and Palacio, Sebastian and Hees, Jörn and Dengel, Andreas},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances},
  year={2023},
  volume={},
  number={},
  pages={1-21},
  doi={10.1109/TPAMI.2023.3243794}}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
