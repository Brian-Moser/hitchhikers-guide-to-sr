<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="This OpenAcess work unwinds some of the most representative advances in the crowded field of SR.">
  <meta property="og:title" content="Hitchhiker's Guide to Super-Resolution"/>
  <meta property="og:description" content="This OpenAcess work unwinds some of the most representative advances in the crowded field of SR."/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Hitchhiker's Guide to Super-Resolution">
  <meta name="twitter:description" content="This OpenAcess work unwinds some of the most representative advances in the crowded field of SR.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Image Super Resolution Survey Paper, Image Super-Resolution, SR, Overview, Review, Survey, TPAMI">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://brian-moser.github.io/" target="_blank">Brian B. Moser</a><sup></sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.de/citations?user=Jx9-sU0AAAAJ&hl=en" target="_blank">Federico Raue</a><sup></sup>,</span>
                  <span class="author-block">
                    <a href="https://stanifrolov.github.io/" target="_blank">Stanislav Frolov</a><sup></sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://spalaciob.github.io/" target="_blank">Sebastian Palacio</a><sup></sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://joernhees.de/blog/" target="_blank">Jörn Hees</a><sup></sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://agd.cs.uni-kl.de/" target="_blank">Andreas Dengel</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">German Research Center for Artificial Intelligence<br>RPTU Kaiserslautern-Landau<br>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10041995" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://ieeexplore.ieee.org/ielx7/34/4359286/10041995/supp1-3243794.pdf?arnumber=10041995" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2209.13131" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            With the advent of Deep Learning (DL), Super-Resolution (SR) has also become a thriving research area. However, despite promising results, the field still faces challenges that require further research e.g., allowing flexible upsampling, more effective loss functions, and better evaluation metrics. We review the domain of SR in light of recent advances, and examine state-of-the-art models such as diffusion (DDPM) and transformer-based SR models. We present a critical discussion on contemporary strategies used in SR, and identify promising yet unexplored research directions. We complement previous surveys by incorporating the latest developments in the field such as uncertainty-driven losses, wavelet networks, neural architecture search, novel normalization methods, and the latests evaluation techniques. We also include several visualizations for the models and methods throughout each chapter in order to facilitate a global understanding of the trends in the field. This review is ultimately aimed at helping researchers to push the boundaries of DL applied to SR.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <div class="content has-text-justified">
      <p style="text-align:center;">
        <img src="static/images/sr_framework.png" alt="MY ALT TEXT" width="50%" height="50%"/>
      </p>
      <p>
        Super-Resolution (SR) is the process of enhancing Low-Resolution (LR) images to High-Resolution (HR). 
        The applications range from natural images to highly advanced satellite, and medical imaging.
        Despite its long history, SR remains a challenging task in computer vision because it is notoriously ill-posed: several HR images can be valid for any given LR image due to many aspects like brightness and coloring.
        The fundamental uncertainties in the relation between LR and HR images pose a complex research task.
        Thanks to rapid advances in Deep Learning (DL), SR has made significant progress in recent years.
        Unfortunately, entry into this field is overwhelming because of the abundance of publications.
        It is knotty work to get an overview of the advantages and disadvantages between publications.
        This OpenAcess work unwinds some of the most representative advances in the crowded field of SR.
        It discusses common knowledge in image SR, standard procedures, and, most importantly, recent advances and future directions.
        New researchers will find this work as an easy starting point to get into the topic of image SR and more advanced researchers will get updated on current trends and can use this work as reference for known procedures, metrics and explanations.
      </p>
      <p>
        The work commences with an introduction to the basic definitions and terminology.
        It then proceeds to discuss evaluation metrics for SR solutions.
        Along the way, we introduce various datasets that provide diverse data types, like 8K resolution images or video sequences.
        It further delves into a discussion of different learning objectives of Super-Resolution:
        Regression-based SR (also with uncertainty), Generative SR, and, more recently, Denoising Diffusion Probabilistic Models.
      </p>
      <p style="text-align:center;">
        <img src="static/images/udl.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
      <p>
        This work also dives into the world of various upsampling methods, a critical aspect of image SR.
        It covers the whys and hows of interpolation-based and learning-based upsampling techniques and also problems appearing with upsampling techniques (e.g., artifacts) in supplemental material.
        Also, our work explores the challenges and potential solutions of flexible upsampling for real-world scenarios with arbitrary scaling factors.
      </p>

      <p>
        Moreover, it surveys additional learning strategies such as curriculum learning, enhanced predictions, learned degradation, network fusion, multi-task learning, and normalization techniques like the Adaptive Deviation Modulator (AdaDM).
      </p>
      <p style="text-align:center;">
        <img src="static/images/MetaUpscale.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
      <p>
        This paper examines in detail different SR models and architectures and provides comprehensive explanations as well as unified visualizations.
        Architectures are categorized into different branches of image SR, such as:
        Pre-upsampling, Post-upsampling, Progressive Upsampling, and Iterative Up-and-Down Upsampling.
      </p>
      <p style="text-align:center;">
        <img src="static/images/frameworks.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
      <p>
        We discuss these primary categories: Simple Networks, Residual Networks, Recurrent-Based Networks, Lightweight and Wavelet-based Models.
        These various state-of-the-art architectures are examined with their pros and cons.
        Finally, you will get a scoop of Unsupervised SR and Neural Architecture Search for SR!
        At last, but not least, we will discuss the future of SR and the challenges that lie ahead.
        So, gather your party and embark on this thrilling adventure, delving into the diverse and intricate world of deep learning-based super-resolution networks and unlock its secrets!
        Spoiler-Warning: Big tables included.
      </p>

      <p style="text-align:center;">
        <img src="static/images/table.png" alt="MY ALT TEXT"  width="50%" height="50%"/>
      </p>
    </div>
  </div>
</div>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@ARTICLE{10041995,
  author={Moser, Brian B. and Raue, Federico and Frolov, Stanislav and Palacio, Sebastian and Hees, Jörn and Dengel, Andreas},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances},
  year={2023},
  volume={},
  number={},
  pages={1-21},
  doi={10.1109/TPAMI.2023.3243794}}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
